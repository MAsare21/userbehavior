{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311d45a-1816-408d-87a8-3b6415885244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import json\n",
    "import collections\n",
    "import more_itertools\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tqdm\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "import mmap\n",
    "from tqdm import tqdm\n",
    "import openpyxl\n",
    "import more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3979a-3abd-4d92-8712-6916eecfdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data -- import/upload xlsx spreadsheet\n",
    "data = pd.read_excel('/pscratch/sd/m/masare/sacct/incident_sla_AY23_complete.xlsx')\n",
    "#data = pd.read_excel('/pscratch/sd/m/masare/sacct/incident_sla.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65004a56-2acd-441f-aeed-22cbeb8c6991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57ad3d-21c5-4d4a-b0a8-d513a030eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533b05f-90b1-41bb-8f41-b4c3f90d888f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f06a7c-dc2e-4a27-a805-d2b662017f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename Colum 'Number' to 'ID' into the dataframe\n",
    "data = data.rename(columns={\"Number\":\"ID\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b416fa-6052-44a1-a95c-d3f35e807525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns # RECHECK COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abf552-396e-448b-bbaa-bb4c2ef02c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(data)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07790c9-d026-4ff2-aed6-afa4e6db2c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['ID']=data['ID'].astype(str) #ensuring ID column is of string type\n",
    "data['ID']=data['ID'].str[3:] #removing first three characters\n",
    "data['ID']=pd.to_numeric(data['ID'],errors='coerce') #converting ID column into numberic\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc897bb-c007-4fce-a893-034dd0c0b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting desired columns\n",
    "columns_to_keep = ['ID',\n",
    "                 'Created',  \n",
    "                'Title',\n",
    "                'Additional comments',\n",
    "                'Close notes',\n",
    "                'Comments and Work notes',\n",
    "                'Staff work notes (NERSC private)']\n",
    "data = data.loc[:, columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2192942-ef94-4e70-b5a5-9fd1295743f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing spaces from column names\n",
    "data.columns = data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a456a-6621-4822-a62f-24b217f76902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'Created']= pd.to_datetime(data['Created'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce4281-e0ae-42b5-8bf1-931395efccaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dfb2e-e600-4823-9246-bdbacf7fe2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8743d-9c16-459c-b837-4504400fcda2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert columns from object to str. I have to use \".loc\" to avoid the copy warning\n",
    "object_columns =[ 'Title', \n",
    "                 'Additionalcomments', \n",
    "                 'Closenotes',\n",
    "                 'CommentsandWorknotes', \n",
    "                 'Staffworknotes(NERSCprivate)']\n",
    "for col in object_columns:\n",
    "    data.loc[:, col] = data.loc[:, col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c9eb8-8030-456f-b7ba-458a247101fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean \n",
    "   #isolate import columns, drop unimportant columns\n",
    "   #remove time stamps (can look at my code and use that) \n",
    "\n",
    "\n",
    "text_cols = [ 'Created', \n",
    "             'Title',\n",
    "            'Additionalcomments',\n",
    "             'Closenotes',\n",
    "            'CommentsandWorknotes',\n",
    "           'Staffworknotes(NERSCprivate)'\n",
    "            ]\n",
    "\n",
    "data = data[['ID'] + text_cols].copy()\n",
    "data.fillna('', inplace=True)\n",
    "data = data.astype(str)\n",
    "\n",
    "## EP -- Let's use this cell to name the columns we want our data frame. This is a little different than what I did in\n",
    "# 'ticket_text_mine.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80f521-871f-4a23-b433-20112cf1f071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[text_cols[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe742d-d46b-4e2a-8eb7-9f648ee42aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DATA CLEANING AND ISOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b74969-d533-49ba-9c44-eff17460b7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# :-----------------------------------------------------------------------------\n",
    "#clean \n",
    "   #isolate import columns, drop unimportant columns\n",
    "   #remove time stamps (can look at my code and use that) \n",
    "# Function: process_comment_text\n",
    "# Input: ind -- index from the pandas dataframe that holds the cleaned xlsx data\n",
    "# Output: Single row that includes, index, number, and text columns combined and\n",
    "# #wed jan 18 2023 812 pm 201128 - shane canon (staff work note (nersc private)) \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def process_comment_text(text):\n",
    "    text = re.sub(r'On \\w+, w+ \\d+, d{4} at \\d{2}:\\d{2} \\w{2} \\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+ \\w+ \\(Staff work notes \\(NERSC private\\)\\)','',text)\n",
    "    text = re.sub(r'\\w+, w+ \\d+, d{4} at \\d{2}:\\d{2} \\w{2} \\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+ \\w+ \\(Staff work notes \\(NERSC private\\)\\)','',text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+ \\w+ \\(Additional comments\\)', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+-\\w+ \\w+ \\(Additional comments\\)', '', text)\n",
    "#the new ones above seems not to work\n",
    "\n",
    "\n",
    "    # Removing timestamps\n",
    "    #text = re.sub(r'\\b\\w{3}\\s+\\w{3}\\s+\\d{1,2}\\s+\\d{4}\\s+\\d{1,2}:\\d{2}\\s+\\w{2}\\b', '', text)\n",
    "    #text = re.sub(r'\\b\\w{3}\\s+\\w{3}\\s+\\d{1,2}\\s+\\d{4}\\s+\\d{1,2}\\d{2}\\s+\\w{2}\\b', '', text, flags=re.IGNORECASE)\n",
    "    #text = re.sub(r'\\b(?:mon|tue|wed|thu|fri|sat|sun)\\s+(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\s+\\d{1,2}\\s+\\d{4}\\s+\\d{1,2}[:]\\d{2}\\s+\\w{2}\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\w{3}\\s+\\w{3}\\s+\\d{1,2}\\s+\\d{4}\\s+\\d{1,2}\\d{2}\\s+\\w{2}\\b', '', text) \n",
    "    #text = re.sub(r'\\b\\(?:sat|sun|mon|tue|wed|thu|fri)\\.?(?:\\w*day)?\\s?\\b', '',text)\n",
    "    #mon[a-z\\.]*\\s+|tue[a-z\\.]*\\s+|wed[a-z\\.]*\\s+|thu[a-z\\.]*\\s+|fri[a-z\\.]*\\s+|sat[a-z\\.]*\\s+|sun[a-z\\.]*\\s+\n",
    "\n",
    "    \n",
    "    # Removing bracketed content\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    # Removing extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    #Removing names\n",
    "    #text = re.sub(r'\\b[a-zA-Z][a-z]*\\b(?:\\s+[a-zA-Z][a-z]*)*', '', text) \n",
    "    text = re.sub(r'\\b[a-zA-Z-]+$\\b','', text)\n",
    "    #phone numbers\n",
    "    text = re.sub(r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d','', text)\n",
    "  \n",
    "    \n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - Guest \\(Additional comments\\)', '', text)\n",
    "    text  = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - System \\(Additional comments\\)', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+ \\w+ \\(Additional comments\\)', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - \\w+ \\w+ \\(Staff work notes \\(NERSC private\\)\\)', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} - Guest \\(Staff work notes \\(NERSC private\\)\\)', '', text)\n",
    "    text = re.sub(r'@\\w+ \\w+', '', text)\n",
    "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2}', '', text)\n",
    "    # text_data = re.sub(r'\\d{2}:\\d{2}:\\d{2}', '', text) #remove system times\n",
    "    # text_data = re.sub(r'\\(Additional comments\\)', '', text)\n",
    "    # text_data = re.sub(r'\\(Staff work notes \\(NERSC private\\)\\)', '', text)\n",
    "   \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML links\n",
    "    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', text)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    # text = re.sub(r'\\.','', text)\n",
    "    text = re.sub(r',','', text)\n",
    "    text = re.sub(r':','', text)\n",
    "    text = re.sub(r'\\?','', text)\n",
    "    \n",
    "    # Remove specific words like 'hi', 'hello'\n",
    "    unwanted_words = ['hi', 'hello','email','organization','laboratory', 'state','bye','mr','thanks','day']\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(unwanted_words))\n",
    "    text = re.sub(pattern, '', text)\n",
    "    \n",
    "    #remove phonenumber and emails\n",
    "    phone_pattern = r'(\\+?\\d{1,2}[-.\\s]?)?(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}'\n",
    "    text = re.sub(phone_pattern, '', text)\n",
    "    \n",
    "    email_pattern = r'[\\w]+@[\\w]+.\\w{3}'\n",
    "    text = re.sub(email_pattern, '', text)\n",
    "        \n",
    "        \n",
    "    # removing quotes can be problematic\n",
    "    # text = re.sub(r'\\\"','', text)\n",
    "    # text = re.sub(r'\\'','', text)\n",
    "    text = text.split()\n",
    "    wl = WordNetLemmatizer()\n",
    "    text = [wl.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cadd8-b40e-46ea-961a-c8292ba3ca56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for col in text_cols: \n",
    "    if col not in data.columns: \n",
    "        raise ValueError(f\"Column '{col}' not found in DataFrame\") \n",
    "\n",
    "\n",
    "data[text_cols] = data[text_cols].fillna('').astype(str)\n",
    "# Concatenate the text columns\n",
    "data['text_data'] = data[text_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "# Apply the cleaning function\n",
    "data['text_data'] = data['text_data'].apply(process_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f15c2-03fe-4412-8eeb-b24b4263ba36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data = data[['ID','Created','text_data']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9b136-4664-438f-b22e-d5a222a538e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60679e5-edee-46db-843a-1917e433b7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('/global/u2/m/masare/ticket-text-analysis/ticket_cleaned.csv', index=False)\n",
    "#data_df = pd.read_csv('/global/u2/m/masare/ticket-text-analysis/Ticket.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3405f17-15f3-417f-b136-a8b090e86e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['text_data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcc690-edeb-4516-a35b-832bea5b8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b754a-a528-4e71-ae53-04d267fda052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a05b5-e899-48dc-8a47-927d81a46f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Remove named entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]:  # Consider adding other relevant types if needed\n",
    "            text = text.replace(ent.text, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc178b-a340-4f64-98d7-e3f7b4ff8140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " data['cleaned_text'] = data['text_data'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c377c31-fac8-490c-8e30-be794278277b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data[['cleaned_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e393471-7d63-4a0d-a2ba-49f660a1b027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data['text_data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00401e29-84ad-4b04-9201-2d32b03db7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = cleaned_data['text_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0d578-15ec-4055-b659-47fbd3a478c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0f594-7367-4084-99cc-d5da185a9242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d9b36-05d7-405d-a8cc-8cfeee7343cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dac6b2-3239-44e8-b3ba-fbf50d73d00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232e971-2a99-4b0f-a3de-f0dc091f94cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_text.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501578f-3a98-4777-a64e-979f55982cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_entity_names(text):\n",
    "  doc = nlp(text)\n",
    "  new_text = []\n",
    "  for token in doc:\n",
    "    if token.ent_type_ == \"\":\n",
    "      new_text.append(token.text)\n",
    "    else:\n",
    "      new_text.append(\" \")\n",
    "  return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8cf49-f1ea-4da9-ad0a-bb1a0a083a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data['text_column_no_entities'] = cleaned_data['text_data'].apply(remove_entity_names)\n",
    "\n",
    "\n",
    "\n",
    "#cleaned_data['text_data'] = cleaned_data['text_data'].apply(unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88123f8c-cc81-4394-9421-6ce2561f12cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cleaned_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c90505-9ad1-4157-81f2-0d5daf5b8971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data['text_column_no_entities'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ecb83-6acd-4a89-b070-ed1897617d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc1 =  cleaned_data['text_column_no_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a403b5-d7a3-45e5-a378-e7bb9f29b7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from spacy import displacy\n",
    "#displacy.render(doc1, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624d657-4d96-405a-b9a5-531a1525b12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc1 in cleaned_data['text_column_no_entities']:\n",
    "  doc1 = nlp(doc1)\n",
    "  displacy.render(doc1, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389e072-4895-4025-b78b-9499cae2a436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_dates(text):\n",
    "  doc = nlp(text)\n",
    "  new_text = []\n",
    "  for token in doc:\n",
    "    if token.ent_type_ == \"DATE\":\n",
    "      new_text.append(\" \")\n",
    "    else:\n",
    "      new_text.append(token.text)\n",
    "  return \" \".join(new_text)\n",
    "\n",
    "cleaned_data['text_column_no_dates'] = cleaned_data['text_column_no_entities'].apply(remove_dates)\n",
    "\n",
    "for doc1 in cleaned_data['text_column_no_dates']:\n",
    "  doc1 = nlp(doc1)\n",
    "  displacy.render(doc1, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e2319-c928-450b-b7d5-a48106818a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc1, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a409481-b397-4d41-a442-ccf436beb079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sacct",
   "language": "python",
   "name": "sacct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
